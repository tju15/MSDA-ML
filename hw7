from surprise import Dataset
from surprise import Reader
import os

file_path = os.path.expanduser('restaurant_ratings.txt')
reader = Reader(line_format='user item rating timestamp', sep='\t')
data = Dataset.load_from_file(file_path, reader=reader)


from surprise import SVD
from surprise.model_selection import cross_validate

import numpy as np
import random

my_seed = 0
random.seed(my_seed)
np.random.seed(my_seed)


''' START '''

''' QUESTION 5'''
print("\n\nSVD:")
algo = SVD()
perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose = 'True')

''' QUESTION 6'''
print("\n\nPMF:")
algo = SVD(biased=False) #PMF
perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose = 'True')

''' QUESTION 7'''
print("\n\nNMF:")
from surprise import NMF
algo = NMF()
perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose = 'True')

''' QUESTION 8'''
print("\n\nUser-Based:")
from surprise import KNNBasic

algo = KNNBasic(sim_options = {'user_based': True })
perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose = 'True')

''' QUESTION 9'''
print("\n\nItem-Based")
algo = KNNBasic(sim_options = {'user_based': False })
perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose = 'True')


''' QUESTION 14'''
import matplotlib.pyplot as plt
import matplotlib
from surprise.model_selection import KFold
import numpy as np
import statistics

print('\nQuestion 14')
means = {'MSD': [], 'COSINE': [], 'PEARSON': []}
means2 = {'MSD': [], 'COSINE': [], 'PEARSON': []}

kfold = KFold(n_splits = 3, random_state = 23, shuffle = True)
algo = KNNBasic(sim_options = {'name': 'MSD', 'user_based': True})
perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = False)
means['MSD'].append(statistics.mean(perf['test_rmse']))
means2['MSD'].append(statistics.mean(perf['test_mae']))

algo = KNNBasic(sim_options = {'name': 'cosine', 'user_based': True})
perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = False)
means['COSINE'].append(statistics.mean(perf['test_rmse']))
means2['COSINE'].append(statistics.mean(perf['test_mae']))


algo = KNNBasic(sim_options = {'name': 'pearson', 'user_based': True})
perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = False)
means['PEARSON'].append(statistics.mean(perf['test_rmse']))
means2['PEARSON'].append(statistics.mean(perf['test_mae']))


algo = KNNBasic(sim_options = {'name': 'MSD', 'user_based': False})
perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = False)
means['MSD'].append(statistics.mean(perf['test_rmse']))
means2['MSD'].append(statistics.mean(perf['test_mae']))


algo = KNNBasic(sim_options = {'name': 'cosine', 'user_based': False})
perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = False)
means['COSINE'].append(statistics.mean(perf['test_rmse']))
means2['COSINE'].append(statistics.mean(perf['test_mae']))


algo = KNNBasic(sim_options = {'name': 'pearson', 'user_based': False})
perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = True)
means['PEARSON'].append(statistics.mean(perf['test_rmse']))
means2['PEARSON'].append(statistics.mean(perf['test_mae']))


barWidth = 0.25
r1 = np.arange(1,3)
r2 = [x + barWidth for x in r1]
r3 = [x + 2*barWidth for x in r1]

fig, ax = plt.subplots()
# RMSE
# p1 = ax.bar(r1, means['MSD'], width = barWidth, label = "MSD")
# p2 = ax.bar(r2, means['COSINE'], width = barWidth, label = "Cosine")
# p3 = ax.bar(r3, means["PEARSON"], width = barWidth, label = "Pearson")

# MAE
p1 = ax.bar(r1, means2['MSD'], width = barWidth, label = "MSD")
p2 = ax.bar(r2, means2['COSINE'], width = barWidth, label = "Cosine")
p3 = ax.bar(r3, means2["PEARSON"], width = barWidth, label = "Pearson")

ax.set_ylabel("MAE Score")
ax.set_xlabel("Metric")
ax.set_title("Comparing Metrics for User and Item Based Collaborative Filtering")
ax.set_xticks(r2)
ax.set_xticklabels(["User-Based", "Item-Based"])
ax.set_ylim([0.75, 0.85])
plt.legend()
ax.autoscale_view()
plt.show()

print('\nQuestion 15')
userList = []
itemList = []
for i in range(25, 51):
    algo = KNNBasic(k = i, sim_options = {'name': 'MSD', 'user_based': True})
    perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = False)
    userList.append(statistics.mean(perf['test_rmse']))

print(userList)
for i in range(25, 51):
    algo = KNNBasic(k = i, sim_options = {'name': 'MSD', 'user_based': False})
    perf = cross_validate(algo, data, cv = kfold, return_train_measures = True, verbose = False)
    itemList.append(statistics.mean(perf['test_rmse']))
barWidth = 0.25
r1 = np.arange(25,51)
r2 = [x + barWidth for x in r1]
r3 = [x + 0.125 for x in r1]

fig, ax = plt.subplots()
p1 = ax.bar(r1, userList, width = barWidth, label = "User-Based")
p2 = ax.bar(r2, itemList, width = barWidth, label = "Item-Based")
# p3 = ax.bar(r3, means["PEARSON"], width = barWidth, label = "Pearson")

ax.set_ylabel("RMSE Score")
ax.set_xlabel("Value of K")
ax.set_title("Comparing MSD Performance with K in User and Item-Based Collaborative Filtering")
ax.set_xticks(r3)
ax.set_xticklabels(r1)
for index, label in enumerate(ax.xaxis.get_ticklabels()):
    if index % 5 != 0:
        label.set_visible(False)
ax.set_ylim([0.98, 1.0])
plt.legend()
ax.autoscale_view()
plt.show()
